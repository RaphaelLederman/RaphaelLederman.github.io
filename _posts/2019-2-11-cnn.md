---
published: true
title: Convolutional Neural Networks
collection: dl
layout: single
author_profile: false
read_time: true
categories: [deeplearning]
excerpt : "Deep Neural Networks"
header :
    overlay_image: "https://maelfabien.github.io/assets/images/wolf.jpg"
    teaser_image: "https://maelfabien.github.io/assets/images/wolf.jpg"
comments : true
toc: true
toc_sticky: true
---

Convolutional Neural Network (CNN) are feed-forward neural network that are mostly used for computer vision. They offer an automated image pre-treatment as well as a dense neural network part. CNNs are special types of neural networks for processing datas with grid-like topology. The architecture of the CNN is inspired by the visual cortex of animals.

{% highlight python %}
{% endhighlight %}

<script type="text/javascript" async
    src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML">
</script>

![image](https://maelfabien.github.io/assets/images/CNN.png)

In previous approaches, a great part of the work was to select the filters (e.g Gabor filters) and the architecture of the filters in order to extract as much information from the image as possible. With the rise of deep learning and greater computation capacities, this work can now be automated. The name of the CNNs comes from the fact that we convolve the initial image input with a set of filters. The parameter to choose remains the number of filters to apply, and the dimension of the filters. The dimension of the filter is called the stride length. Typical values for the stride lie between 2 and 5.

In some sense, we are building a convolved output that has a volume. It's no longer a 2 dimensional picture. The filters are hardly humanly understandable, especially when we use a lot of them. Some are used to find curves, other edges, other textures... 

Mathematically, the convolution is expressed as such :
$$ (f * g)(t) = \int_{-\infty}^{+\infty} f(\tau)g(t-\tau) \partial \tau $$

The convolution represents the percentage of area of the filter \(g\) that overlaps with the input $$ f $$ at time $$ \tau $$ over all time $$ t $$ . However, since $$ \tau < 0 $$ and $$ \tau > t $$ have no meaning, the convolution is described as :

$$ (f * g)(t) = \int_{0}^{t} f(\tau)g(t-\tau) \partial \tau $$

At each convolution step, for each input, we apply an activation function (usually ReLU). So far, we have only added dimensionality to our initial image input. We then apply a so-called pooling. Pooling involves a down sampling of features so that we need to learn less parameters when training. The most common form of pooling is max-pooling. For each of the dimension of each of the input image, we perform a max-pooling that takes, over a given height and width, typically 2x2, the maximum value among the 4 pixels. The intuition is that the maximal value has higher chances to be more significant when classifying an image. 

We have now covered all the ingredients of a convolution neural network :
- the convolution layer
- the activation
- the pooling layer
- the fully connected layer, similar to a dense neural network

The order of the layers can be switched :

$$ ReLU(MaxPool(Conv(X))) = MaxPool(ReLU(Conv(X))) $$

In image classification, we usually add several layers of convolution and pooling. This allows us to model more complex structures. Most of the model tuning in deep learning is to determine the optimal model structure. Some famous algorithms developed by Microsoft or Google reach a depth of more than 150 hidden layers. 

Implementing a CNN in Keras can be done the following way :
```python
def createModel2():

    model = Sequential() 

    model.add(Conv2D(32, (3, 3), padding='same', activation='relu', 
    input_shape=input_shape))
    model.add(MaxPooling2D(pool_size=(2, 2)))
    model.add(BatchNormalization())

    model.add(Conv2D(32, (3, 3), activation='relu'))
    model.add(MaxPooling2D(pool_size=(2, 2)))
    model.add(BatchNormalization())

    model.add(Conv2D(32, (3, 3), padding='same', activation='relu'))
    model.add(MaxPooling2D(pool_size=(2, 2)))

    model.add(Conv2D(32, (3, 3), padding='same', activation='relu'))

    model.add(Flatten())
    model.add(Dense(512, activation='relu'))
    model.add(Dense(nClasses, activation='softmax'))

    return model
```

As you can see, we add several convolution, max pooling and batch normalization layers, before flattening the output of the layers and adding several dense layers. The final dense layer here contains the number of classes we are working with in the inputs.

> **Conclusion** : CNNs are nowadays key elements in computer vision. I have recently been working on a facial emotion recognition algorithm. The structure of the model implemented is very similar to the one exposed above.
